{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This notebook was used to scrape model_size information from HuggingFace so that the model_size can also be presented. This Model size is a better parameter to make a decision on using these models for production environmetns.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814a8b0a1f16d950"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:19:36.307823Z",
     "start_time": "2024-03-20T19:19:36.276520Z"
    }
   },
   "outputs": [],
   "source": [
    "import ssl \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def get_model_size(model_name, hf_access_token):\n",
    "    url = f\"https://huggingface.co/timm/{model_name}/tree/main\"\n",
    "    headers = {\"Authorization\": f\"Bearer {hf_access_token}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        page_soup = soup(response.content, \"html.parser\")\n",
    "        all_file_sizes = page_soup.find_all('a', {'title' : 'Download file'})\n",
    "        selected_file = [file for file in all_file_sizes if \"pytorch_model.bin\" in file['href']]\n",
    "        model_size = selected_file[0].text\n",
    "        model_size = model_size.split(\"\\n\")[0]\n",
    "    elif response.status_code == 404:\n",
    "        model_size = \"Model Not Found\"\n",
    "    elif response.status_code == 401:\n",
    "        model_size = \"Model Authorization Error\"\n",
    "    else:\n",
    "        raise Exception(f\"Error in getting model size for {model_name}\")\n",
    "    return model_size\n",
    "\n",
    "def get_model_sizes(model_names, size_csv_path, hf_access_token):\n",
    "    model_sizes = []\n",
    "    count = 0\n",
    "    #get the idx from whcih we have to resume from the csv file:\n",
    "    try:\n",
    "        model_size_df = pd.read_csv(size_csv_path, header=None)\n",
    "        model_shape = model_size_df.shape\n",
    "        model_resume_idx = model_shape[0]\n",
    "        print(f\"Resuming from index {model_resume_idx}\")\n",
    "    except FileNotFoundError:\n",
    "        model_resume_idx = 0\n",
    "    \n",
    "    if model_resume_idx == len(model_names):\n",
    "        print(\"All models have been scraped\")\n",
    "        return model_size_df\n",
    "    else:\n",
    "        for model_name in tqdm(model_names[model_resume_idx:]):\n",
    "            model_size = get_model_size(model_name, hf_access_token)\n",
    "            model_sizes.append(model_size)\n",
    "            with open(size_csv_path, \"a\") as f:\n",
    "                f.write(f\"{model_name},{model_size}\\n\")\n",
    "            count += 1\n",
    "            if count % 45 == 0:\n",
    "                time.sleep(30)\n",
    "        \n",
    "        model_size_df = pd.read_csv(size_csv_path)\n",
    "        return model_size_df\n",
    "\n",
    "\n",
    "def get_size_in_mb(combined_df):\n",
    "    model_sizes = combined_df.model_size[combined_df.model_size.notnull()].copy()\n",
    "    \n",
    "    conversion_df = pd.DataFrame(columns=[\"original_size\"])\n",
    "    conversion_df['original_size'] = model_sizes\n",
    "    conversion_df.reset_index(inplace=True, drop=True) \n",
    "    conversion_df['metric'] = conversion_df.original_size.apply(lambda x: x.split(\" \")[1] if x is not np.nan else np.nan)\n",
    "    conversion_df['size'] = conversion_df.original_size.apply(lambda x: float(x.split(\" \")[0]) if x is not np.nan else np.nan)\n",
    "    conversion_df['multiplier'] = conversion_df.metric.apply(lambda x: 1 if x == \"MB\" else 1024)\n",
    "    conversion_df[\"size_in_mb\"] = conversion_df['size'] * conversion_df['multiplier']\n",
    "    \n",
    "    return conversion_df['size_in_mb'].values\n",
    "\n",
    "def get_combined_df(score_df, model_size_df):\n",
    "    combined_df = pd.concat([score_df, model_size_df], axis=1)\n",
    "    combined_df.rename(columns={1: \"model_size\"}, inplace=True)\n",
    "    combined_df.drop(columns=[0], inplace=True)\n",
    "    combined_df = combined_df.loc[:,['model', 'model_size','top1', 'top1_err', 'top5', 'top5_err', 'param_count',\n",
    "           'img_size', 'crop_pct', 'interpolation', 'top1_diff', 'top5_diff',\n",
    "           'rank_diff']]\n",
    "    \n",
    "    combined_df.model_size = combined_df.model_size.apply(lambda x: np.nan if x in [\"Model Not Found\", \"Model Authorization Error\"] else x)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def get_final_df(score_df_path, scraped_size_path, hf_access_token):\n",
    "    score_df = pd.read_csv(score_df_path)\n",
    "    \n",
    "    #get Model Sizes from HunggingFace library\n",
    "    model_size_df = get_model_sizes(score_df['model'].values,\n",
    "                                    scraped_size_path, \n",
    "                                    hf_access_token)\n",
    "    \n",
    "    #combine the original and final_dfs\n",
    "    combined_df = get_combined_df(score_df, model_size_df)\n",
    "    \n",
    "    #convert the model sizes to MB. Leaving out the models which are not found.\n",
    "    sizes_in_mb = get_size_in_mb(combined_df)\n",
    "    nonnull_idx = combined_df.model_size[combined_df.model_size.notnull()].index\n",
    "    combined_df.loc[nonnull_idx, 'model_size_in_mb'] = sizes_in_mb\n",
    "    \n",
    "    #A final dataframe with only the required columns\n",
    "    final_cols = ['model', 'model_size_in_mb','top1', 'top1_err', 'top5', 'top5_err', 'param_count',\n",
    "               'img_size', 'crop_pct', 'interpolation', 'top1_diff', 'top5_diff',\n",
    "               'rank_diff']\n",
    "    \n",
    "    final_df = combined_df.loc[:, final_cols].copy()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index 1080\n",
      "All models have been scraped\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                model  model_size_in_mb  \\\n0      eva02_large_patch14_448.mim_m38m_ft_in22k_in1k           1249.28   \n1                  eva_giant_patch14_336.clip_ft_in1k           4147.20   \n2     eva02_large_patch14_448.mim_in22k_ft_in22k_in1k           1249.28   \n3            eva_giant_patch14_560.m30m_ft_in22k_in1k           4157.44   \n4           eva02_large_patch14_448.mim_in22k_ft_in1k           1249.28   \n...                                               ...               ...   \n1075                        efficientvit_m0.r224_in1k              9.76   \n1076                               lcnet_050.ra2_in1k              7.60   \n1077            tf_mobilenetv3_small_minimal_100.in1k              8.29   \n1078                                   tinynet_e.in1k              8.30   \n1079                  mobilenetv3_small_050.lamb_in1k              6.48   \n\n        top1  top1_err    top5  top5_err param_count  img_size  crop_pct  \\\n0     91.129     8.871  98.713     1.287      305.08       448     1.000   \n1     91.058     8.942  98.602     1.399    1,013.01       336     1.000   \n2     91.022     8.978  98.683     1.317      305.08       448     1.000   \n3     90.969     9.031  98.672     1.328    1,014.45       560     1.000   \n4     90.920     9.080  98.685     1.315      305.08       448     1.000   \n...      ...       ...     ...       ...         ...       ...       ...   \n1075  71.091    28.909  89.589    10.411        2.35       224     0.875   \n1076  70.402    29.598  88.825    11.175        1.88       224     0.875   \n1077  70.096    29.904  88.516    11.485        2.04       224     0.875   \n1078  66.810    33.190  86.280    13.720        2.04       106     0.875   \n1079  64.697    35.303  84.858    15.142        1.59       224     0.875   \n\n     interpolation  top1_diff  top5_diff  rank_diff  \n0          bicubic      1.077     -0.335          0  \n1          bicubic      1.592     -0.224          5  \n2          bicubic      1.052     -0.329         -1  \n3          bicubic      1.183     -0.320         -1  \n4          bicubic      1.298     -0.265         -1  \n...            ...        ...        ...        ...  \n1075       bicubic      7.821      4.413          0  \n1076       bicubic      7.264      4.443          0  \n1077      bilinear      7.202      4.278          0  \n1078       bicubic      6.944      4.518          0  \n1079       bicubic      6.781      4.678          0  \n\n[1080 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>model_size_in_mb</th>\n      <th>top1</th>\n      <th>top1_err</th>\n      <th>top5</th>\n      <th>top5_err</th>\n      <th>param_count</th>\n      <th>img_size</th>\n      <th>crop_pct</th>\n      <th>interpolation</th>\n      <th>top1_diff</th>\n      <th>top5_diff</th>\n      <th>rank_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>eva02_large_patch14_448.mim_m38m_ft_in22k_in1k</td>\n      <td>1249.28</td>\n      <td>91.129</td>\n      <td>8.871</td>\n      <td>98.713</td>\n      <td>1.287</td>\n      <td>305.08</td>\n      <td>448</td>\n      <td>1.000</td>\n      <td>bicubic</td>\n      <td>1.077</td>\n      <td>-0.335</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>eva_giant_patch14_336.clip_ft_in1k</td>\n      <td>4147.20</td>\n      <td>91.058</td>\n      <td>8.942</td>\n      <td>98.602</td>\n      <td>1.399</td>\n      <td>1,013.01</td>\n      <td>336</td>\n      <td>1.000</td>\n      <td>bicubic</td>\n      <td>1.592</td>\n      <td>-0.224</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eva02_large_patch14_448.mim_in22k_ft_in22k_in1k</td>\n      <td>1249.28</td>\n      <td>91.022</td>\n      <td>8.978</td>\n      <td>98.683</td>\n      <td>1.317</td>\n      <td>305.08</td>\n      <td>448</td>\n      <td>1.000</td>\n      <td>bicubic</td>\n      <td>1.052</td>\n      <td>-0.329</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eva_giant_patch14_560.m30m_ft_in22k_in1k</td>\n      <td>4157.44</td>\n      <td>90.969</td>\n      <td>9.031</td>\n      <td>98.672</td>\n      <td>1.328</td>\n      <td>1,014.45</td>\n      <td>560</td>\n      <td>1.000</td>\n      <td>bicubic</td>\n      <td>1.183</td>\n      <td>-0.320</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>eva02_large_patch14_448.mim_in22k_ft_in1k</td>\n      <td>1249.28</td>\n      <td>90.920</td>\n      <td>9.080</td>\n      <td>98.685</td>\n      <td>1.315</td>\n      <td>305.08</td>\n      <td>448</td>\n      <td>1.000</td>\n      <td>bicubic</td>\n      <td>1.298</td>\n      <td>-0.265</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1075</th>\n      <td>efficientvit_m0.r224_in1k</td>\n      <td>9.76</td>\n      <td>71.091</td>\n      <td>28.909</td>\n      <td>89.589</td>\n      <td>10.411</td>\n      <td>2.35</td>\n      <td>224</td>\n      <td>0.875</td>\n      <td>bicubic</td>\n      <td>7.821</td>\n      <td>4.413</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1076</th>\n      <td>lcnet_050.ra2_in1k</td>\n      <td>7.60</td>\n      <td>70.402</td>\n      <td>29.598</td>\n      <td>88.825</td>\n      <td>11.175</td>\n      <td>1.88</td>\n      <td>224</td>\n      <td>0.875</td>\n      <td>bicubic</td>\n      <td>7.264</td>\n      <td>4.443</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1077</th>\n      <td>tf_mobilenetv3_small_minimal_100.in1k</td>\n      <td>8.29</td>\n      <td>70.096</td>\n      <td>29.904</td>\n      <td>88.516</td>\n      <td>11.485</td>\n      <td>2.04</td>\n      <td>224</td>\n      <td>0.875</td>\n      <td>bilinear</td>\n      <td>7.202</td>\n      <td>4.278</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1078</th>\n      <td>tinynet_e.in1k</td>\n      <td>8.30</td>\n      <td>66.810</td>\n      <td>33.190</td>\n      <td>86.280</td>\n      <td>13.720</td>\n      <td>2.04</td>\n      <td>106</td>\n      <td>0.875</td>\n      <td>bicubic</td>\n      <td>6.944</td>\n      <td>4.518</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1079</th>\n      <td>mobilenetv3_small_050.lamb_in1k</td>\n      <td>6.48</td>\n      <td>64.697</td>\n      <td>35.303</td>\n      <td>84.858</td>\n      <td>15.142</td>\n      <td>1.59</td>\n      <td>224</td>\n      <td>0.875</td>\n      <td>bicubic</td>\n      <td>6.781</td>\n      <td>4.678</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1080 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_score_path = \"results-imagenet-real.csv\"\n",
    "scraped_size_path= \"model_sizes.csv\"\n",
    "hf_access_token = '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'\n",
    "\n",
    "get_final_df(orig_score_path, scraped_size_path, hf_access_token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:19:38.202450Z",
     "start_time": "2024-03-20T19:19:38.140058Z"
    }
   },
   "id": "911dcc243bce31ba",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
